{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FloodNet Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "import cv2\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "#import model.resnet as models\n",
    "\n",
    "from torch.optim import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## First Tries"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "image = Image.open(\"data/image/10165.jpg\")\n",
    "image\n",
    "np_image = np.array(image)\n",
    "print(np_image.shape)\n",
    "#print(np_image)\n",
    "print(np.sum(np_image)/np_image.shape[0]/np_image.shape[1]/np_image.shape[2])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#import csv\n",
    "#filename = open(\"FloodNet_split_train_valid_test.csv\", 'r')\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"FloodNet_split_train_valid_test.csv\", sep=',', header=None, names=[\"Column1\", \"Column2\", \"Column3\"])\n",
    "df1 = df[df[\"Column3\"]=='train']\n",
    "df1[\"Column1\"].map(lambda x: \"data/\" + x)#.iloc[1]\n",
    "\n",
    "list(zip(df1[\"Column1\"], df1[\"Column2\"]))  \n",
    "df1['Column1']\n",
    "\n",
    "for entry in list(df['Column1']):\n",
    "    filepath = 'Data/Image/' + entry\n",
    "    image = Image.open(filepath)\n",
    "    np_image = np.array(image)\n",
    "    if np_image.shape[0] != 3000:\n",
    "        print(entry, np_image.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function\n",
    "#code in this cell from https://albumentations.ai/docs/examples/example_kaggle_salt/\n",
    "def visualize(image, mask, original_image=None, original_mask=None):\n",
    "    fontsize = 18\n",
    "    \n",
    "    if original_image is None and original_mask is None:\n",
    "        f, ax = plt.subplots(2, 1, figsize=(8, 8))\n",
    "\n",
    "        ax[0].imshow(image)\n",
    "        ax[1].imshow(mask)\n",
    "    else:\n",
    "        f, ax = plt.subplots(2, 2, figsize=(8, 8))\n",
    "\n",
    "        ax[0, 0].imshow(original_image)\n",
    "        ax[0, 0].set_title('Original image', fontsize=fontsize)\n",
    "        \n",
    "        ax[1, 0].imshow(original_mask)\n",
    "        ax[1, 0].set_title('Original mask', fontsize=fontsize)\n",
    "        \n",
    "        ax[0, 1].imshow(image)\n",
    "        ax[0, 1].set_title('Transformed image', fontsize=fontsize)\n",
    "        \n",
    "        ax[1, 1].imshow(mask)\n",
    "        ax[1, 1].set_title('Transformed mask', fontsize=fontsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FloodData(Dataset):\n",
    "\n",
    "    # mapping between label class names and indices\n",
    "    LABEL_CLASSES = {\n",
    "      'background': \t\t  0,\n",
    "      'building-flooded': \t\t\t    1,\n",
    "      'building-non-flooded': \t  2,\n",
    "      'road-flooded': \t\t\t\t      3,\n",
    "      'road-non-flooded': \t\t\t    4,\n",
    "      'water': \t\t\t    5,\n",
    "      'tree':   6,\n",
    "      'vehicle': \t\t\t\t    7,\n",
    "      'pool': \t\t\t\t    8,\n",
    "      'grass': \t\t\t  9\n",
    "    }\n",
    "   \n",
    "\n",
    "    def __init__(self, transforms=None, split='train'):\n",
    "        \n",
    "        self.transforms = transforms\n",
    "        \n",
    "        SPLIT = pd.read_csv(\"FloodNet_split_train_valid_test.csv\", sep=',', header=None, names=[\"Column1\", \"Column2\", \"Column3\"])\n",
    "        SPLIT[\"Column1\"] = SPLIT[\"Column1\"].map(lambda x: \"Data/image/\" + x)\n",
    "        SPLIT[\"Column2\"] = SPLIT[\"Column2\"].map(lambda x: \"Data/mask/\" + x)\n",
    "        \n",
    "        splitted_set = SPLIT[SPLIT[\"Column3\"]==split]\n",
    "        \n",
    "        # prepare data\n",
    "        self.data = list(zip(splitted_set[\"Column1\"], splitted_set[\"Column2\"]))                                  # list of tuples of (image path, label class)\n",
    "        \"\"\"\n",
    "        images = np.empty((len(self.data)*3000,len(self.data)*4000,3))\n",
    "        \n",
    "        for i in range(len(self.data)):\n",
    "            images[i] = np.array()\n",
    "            Image.open()\n",
    "        \"\"\" \n",
    "            \n",
    "    #TODO: please provide the remaining functions required for the torch.utils.data.Dataset class.\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "    def __getitem__(self, x):\n",
    "        imgName, labelsName = self.data[x]\n",
    "\n",
    "        img = np.array(Image.open(imgName))\n",
    "        labels = np.array(Image.open(labelsName))\n",
    "        if self.transforms is not None:\n",
    "            transformed = self.transforms(image=img, mask=labels)\n",
    "            #code to visualize transformation - uncomment if want to use\n",
    "            #visualize(transformed[\"image\"], transformed[\"mask\"], img, labels)\n",
    "            img = transformed['image']\n",
    "            labels = transformed['mask']\n",
    "        else:\n",
    "            img, labels = img[:3000, :4000,:], labels[:3000, :4000]\n",
    "        \n",
    "        img, labels = torch.tensor(img).float(), torch.tensor(labels)\n",
    "        #move band dimension to the first dimension, because it is expected like this in the model\n",
    "        img = torch.movedim(img, 2, 0)\n",
    "        \n",
    "        return img, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [06:05<00:00, 20.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([106.5385, 116.1601,  87.6059], dtype=torch.float64) tensor([53.1838, 49.5204, 53.5829], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# source of code in this cell:\n",
    "# https://www.binarystudy.com/2021/04/how-to-calculate-mean-standard-deviation-images-pytorch.html\n",
    "\n",
    "train_not_transformed_set = FloodData(transforms = None, split = 'train')\n",
    "train_not_transformed_loader = DataLoader(train_not_transformed_set, batch_size = 16)\n",
    "\n",
    "def batch_mean_and_sd(loader):\n",
    "    count = 0\n",
    "    fst_moment = torch.empty(3)\n",
    "    snd_moment = torch.empty(3)\n",
    "    \n",
    "    for images, _  in tqdm(loader):\n",
    "        b, c, h, w = images.shape #batch, color, height, width\n",
    "        nb_pixels = b*h*w\n",
    "        \n",
    "        sum_ = torch.sum(images, dim = [0,2,3])\n",
    "        sum_of_square = torch.sum(torch.square(images), dim = [0,2,3])\n",
    "        \n",
    "        fst_moment = (count*fst_moment+sum_)/(count+nb_pixels)\n",
    "        snd_moment = (count*snd_moment+sum_of_square)/(count+nb_pixels)\n",
    "\n",
    "        count += nb_pixels\n",
    "        \n",
    "    mean, std = fst_moment, torch.sqrt(snd_moment-fst_moment**2)\n",
    "    return mean, std\n",
    "\n",
    "mean, std = batch_mean_and_sd(train_not_transformed_loader)\n",
    "print(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = A.Compose([\n",
    "    A.RandomSizedCrop(min_max_height = [1000, 2500], height=713, width=713),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.ShiftScaleRotate(p=0.5),\n",
    "    #A.Blur(blur_limit = 3),\n",
    "    A.RandomRotate90(),\n",
    "    #A.OpticalDistortion(),\n",
    "    #A.GridDistortion(),\n",
    "    #A.Resize(height=713, width=713),\n",
    "    \n",
    "    #Normalization is applied by the formula: img = (img - mean * max_pixel_value) / (std * max_pixel_value)\n",
    "    A.Normalize(mean = mean, std = std, max_pixel_value=1)\n",
    "])\n",
    "\n",
    "transform_val = A.Compose([\n",
    "    A.RandomSizedCrop(min_max_height = [500, 2500], height=713, width=713),\n",
    "    #A.Resize(height=713, width=713),\n",
    "    A.Normalize(mean = mean, std = std, max_pixel_value=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FloodData(transforms = transform_train, split = 'train')\n",
    "val_dataset = FloodData(transforms = transform_val, split = 'valid')\n",
    "test_dataset = FloodData(transforms = transform_val, split = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.4614, -0.5178, -0.5742,  ..., -0.4802, -0.3298, -0.1982],\n",
       "          [-0.3486, -0.4802, -0.5366,  ..., -0.3862, -0.4050, -0.2546],\n",
       "          [-0.4802, -0.4614, -0.4802,  ..., -0.4614, -0.5554, -0.3674],\n",
       "          ...,\n",
       "          [-0.3110, -0.4050, -0.3486,  ..., -0.4802, -0.4050, -0.4238],\n",
       "          [-0.2922, -0.3674, -0.3486,  ..., -0.4238, -0.4238, -0.4050],\n",
       "          [-0.2170, -0.2170, -0.2170,  ..., -0.4050, -0.4050, -0.3862]],\n",
       "\n",
       "         [[-1.1745, -1.2552, -1.3158,  ..., -1.1139, -0.9927, -0.8716],\n",
       "          [-1.0533, -1.1947, -1.2552,  ..., -1.0331, -1.0533, -0.9321],\n",
       "          [-1.1947, -1.1543, -1.1543,  ..., -1.1139, -1.2149, -1.0533],\n",
       "          ...,\n",
       "          [-0.9321, -1.0129, -0.9321,  ..., -1.1543, -1.0735, -1.0937],\n",
       "          [-0.9119, -0.9927, -0.9321,  ..., -1.0937, -1.0937, -1.0735],\n",
       "          [-0.8716, -0.8312, -0.8312,  ..., -1.0533, -1.0533, -1.0331]],\n",
       "\n",
       "         [[-1.0378, -1.0564, -1.0937,  ..., -1.0937, -0.9631, -0.8698],\n",
       "          [-0.9258, -1.0191, -1.0378,  ..., -1.0004, -1.0191, -0.9444],\n",
       "          [-1.0378, -0.9818, -0.9444,  ..., -1.0937, -1.1871, -1.0564],\n",
       "          ...,\n",
       "          [-0.7578, -0.7951, -0.7018,  ..., -0.9631, -0.8885, -0.9071],\n",
       "          [-0.7578, -0.8138, -0.7205,  ..., -0.9071, -0.9071, -0.8885],\n",
       "          [-0.7018, -0.7018, -0.6832,  ..., -0.8698, -0.8698, -0.8511]]],\n",
       "\n",
       "\n",
       "        [[[-0.0665, -0.0665, -0.0101,  ...,  0.1403,  0.1403,  0.0651],\n",
       "          [-0.1605, -0.1041, -0.0665,  ...,  0.1027,  0.1591,  0.1779],\n",
       "          [-0.1417, -0.1041, -0.0665,  ...,  0.1403,  0.0087, -0.0853],\n",
       "          ...,\n",
       "          [-0.1229, -0.1229, -0.1229,  ...,  0.5164,  0.3847,  0.4599],\n",
       "          [-0.1605, -0.2358, -0.2170,  ...,  0.5728,  0.2343,  0.4787],\n",
       "          [-0.2358, -0.2734, -0.2546,  ...,  0.5540,  0.4411,  0.4975]],\n",
       "\n",
       "         [[-0.8918, -0.8716, -0.8312,  ..., -0.4677, -0.5081, -0.6090],\n",
       "          [-0.9725, -0.9321, -0.8716,  ..., -0.5081, -0.4677, -0.4677],\n",
       "          [-0.9725, -0.9725, -0.9119,  ..., -0.4879, -0.6292, -0.7302],\n",
       "          ...,\n",
       "          [-0.9119, -0.9119, -0.8514,  ..., -0.3465, -0.4879, -0.4071],\n",
       "          [-0.9523, -1.0129, -0.9523,  ..., -0.2658, -0.6090, -0.3667],\n",
       "          [-1.0129, -1.0533, -0.9927,  ..., -0.2658, -0.3869, -0.3263]],\n",
       "\n",
       "         [[-0.9071, -0.9444, -0.9444,  ..., -0.2539, -0.2726, -0.3846],\n",
       "          [-0.9818, -0.9818, -0.9631,  ..., -0.3099, -0.2726, -0.2912],\n",
       "          [-0.9631, -0.9818, -0.9631,  ..., -0.2912, -0.4592, -0.5712],\n",
       "          ...,\n",
       "          [-0.9444, -0.9444, -0.8885,  ..., -0.4965, -0.6458, -0.6085],\n",
       "          [-0.9631, -1.0004, -0.9444,  ..., -0.4592, -0.7951, -0.6085],\n",
       "          [-0.9818, -1.0004, -0.9444,  ..., -0.4965, -0.6272, -0.5899]]],\n",
       "\n",
       "\n",
       "        [[[ 1.1556,  1.1368,  1.2121,  ...,  1.0428,  1.0428,  1.1933],\n",
       "          [ 1.2121,  1.1744,  1.1933,  ...,  0.9112,  0.9676,  0.8548],\n",
       "          [ 1.3249,  1.2309,  1.2309,  ...,  1.0804,  0.8736,  0.7420],\n",
       "          ...,\n",
       "          [-1.3075, -1.4203, -1.2135,  ...,  2.4342,  2.4718,  2.4718],\n",
       "          [-1.3075, -1.2887, -1.2887,  ...,  2.4342,  2.4342,  2.4530],\n",
       "          [-1.3075, -1.3263, -1.3075,  ...,  2.3778,  2.3778,  2.4530]],\n",
       "\n",
       "         [[ 1.4305,  1.4305,  1.5113,  ...,  1.1276,  1.1478,  1.3094],\n",
       "          [ 1.4709,  1.4709,  1.4911,  ...,  1.0266,  1.0670,  0.9257],\n",
       "          [ 1.5921,  1.4911,  1.5517,  ...,  1.2286,  1.0065,  0.8449],\n",
       "          ...,\n",
       "          [-0.8514, -0.9523, -0.7302,  ...,  2.0767,  2.1373,  2.1373],\n",
       "          [-0.8514, -0.8312, -0.8110,  ...,  2.0969,  2.0969,  2.1171],\n",
       "          [-0.8514, -0.8918, -0.8716,  ...,  2.0363,  2.0363,  2.1373]],\n",
       "\n",
       "         [[ 1.3884,  1.3697,  1.4257,  ...,  0.5672,  0.5859,  0.7352],\n",
       "          [ 1.4630,  1.3884,  1.4071,  ...,  0.3993,  0.5112,  0.3993],\n",
       "          [ 1.5564,  1.4630,  1.4630,  ...,  0.6046,  0.4366,  0.3060],\n",
       "          ...,\n",
       "          [-0.6085, -0.7205, -0.5712,  ...,  2.5641,  2.5641,  2.5641],\n",
       "          [-0.5712, -0.5712, -0.5712,  ...,  2.5268,  2.5268,  2.5455],\n",
       "          [-0.5712, -0.5712, -0.5339,  ...,  2.4708,  2.4708,  2.5641]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 0.0087, -0.0665, -0.0853,  ...,  0.0839,  0.3283,  0.4223],\n",
       "          [ 0.0463, -0.0665, -0.0289,  ...,  0.3847, -0.0477,  0.4223],\n",
       "          [-0.0101, -0.0665, -0.0665,  ..., -0.0665,  0.3283,  0.3659],\n",
       "          ...,\n",
       "          [ 0.1779,  0.2907,  0.3659,  ...,  0.7232,  1.0052,  1.0616],\n",
       "          [ 0.2531,  0.2531,  0.3283,  ...,  0.6292,  0.6668,  0.6480],\n",
       "          [ 0.3283,  0.3659,  0.2155,  ...,  0.6856,  0.7232,  0.7984]],\n",
       "\n",
       "         [[-0.1042, -0.1850, -0.1850,  ...,  0.5218,  0.7843,  0.8853],\n",
       "          [-0.0638, -0.1850, -0.1244,  ...,  0.8449,  0.3804,  0.8853],\n",
       "          [-0.1042, -0.1850, -0.1648,  ...,  0.3603,  0.7843,  0.8247],\n",
       "          ...,\n",
       "          [-0.2456, -0.1446, -0.0840,  ...,  1.0065,  1.3094,  1.3699],\n",
       "          [-0.1850, -0.1850, -0.1042,  ...,  0.8651,  0.9459,  0.9257],\n",
       "          [-0.1042, -0.0638, -0.2254,  ...,  0.9055,  0.9661,  1.0468]],\n",
       "\n",
       "         [[ 0.6046,  0.5112,  0.4739,  ...,  0.2500,  0.4553,  0.5299],\n",
       "          [ 0.6419,  0.5299,  0.5299,  ...,  0.5486,  0.1193,  0.5486],\n",
       "          [ 0.6046,  0.5299,  0.4926,  ...,  0.1007,  0.4926,  0.5112],\n",
       "          ...,\n",
       "          [ 0.1380,  0.2313,  0.3246,  ...,  0.6979,  0.9778,  1.0338],\n",
       "          [ 0.2126,  0.1940,  0.2873,  ...,  0.6046,  0.6419,  0.6232],\n",
       "          [ 0.2873,  0.3246,  0.1753,  ...,  0.6605,  0.6979,  0.7725]]],\n",
       "\n",
       "\n",
       "        [[[ 0.4599,  0.3659,  0.2343,  ...,  0.6104, -0.0101, -0.3486],\n",
       "          [ 0.2907,  0.3471,  0.2907,  ...,  0.1215,  0.1591, -0.2546],\n",
       "          [-0.0477,  0.3283,  0.1779,  ..., -0.6306,  0.2155, -0.3110],\n",
       "          ...,\n",
       "          [-0.1605, -0.2358,  0.3659,  ...,  2.3026,  2.2650,  2.2838],\n",
       "          [-0.0665, -0.1229,  0.0651,  ...,  2.2838,  2.2838,  2.2838],\n",
       "          [ 0.0087, -0.2170,  0.1215,  ...,  2.2838,  2.2838,  2.2650]],\n",
       "\n",
       "         [[ 0.8449,  0.7439,  0.6026,  ...,  1.1882,  0.4814,  0.0977],\n",
       "          [ 0.6632,  0.7237,  0.6632,  ...,  0.6228,  0.6228,  0.1583],\n",
       "          [ 0.2997,  0.7035,  0.5420,  ..., -0.2254,  0.6430,  0.0573],\n",
       "          ...,\n",
       "          [ 0.2593,  0.1583,  0.7843,  ...,  2.2787,  2.2383,  2.2585],\n",
       "          [ 0.3401,  0.2391,  0.4410,  ...,  2.2585,  2.2585,  2.2585],\n",
       "          [ 0.4006,  0.1785,  0.5218,  ...,  2.2585,  2.2585,  2.2383]],\n",
       "\n",
       "         [[ 0.4739,  0.3806,  0.2686,  ...,  0.7352,  0.0820, -0.2912],\n",
       "          [ 0.3060,  0.3619,  0.3060,  ...,  0.2313,  0.2500, -0.1979],\n",
       "          [-0.0300,  0.3433,  0.1940,  ..., -0.4965,  0.3060, -0.2539],\n",
       "          ...,\n",
       "          [-0.0113, -0.0673,  0.5112,  ...,  2.6388,  2.6015,  2.6201],\n",
       "          [ 0.0820,  0.0074,  0.1940,  ...,  2.6201,  2.6201,  2.6201],\n",
       "          [ 0.1940, -0.0113,  0.2873,  ...,  2.6201,  2.6201,  2.6015]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1779,  0.0275, -0.2734,  ...,  2.1898,  2.1522,  2.1146],\n",
       "          [ 0.1779,  0.1403, -0.3110,  ...,  2.1898,  2.1710,  2.1710],\n",
       "          [ 0.1967,  0.2343, -0.3674,  ...,  2.2086,  2.1898,  2.1898],\n",
       "          ...,\n",
       "          [-0.1041,  0.0275, -0.1229,  ..., -0.2734, -0.4238, -0.4990],\n",
       "          [-0.2170,  0.0275,  0.0087,  ..., -0.1417, -0.2546, -0.3674],\n",
       "          [-0.3486,  0.0651,  0.0651,  ..., -0.0853, -0.2170, -0.3298]],\n",
       "\n",
       "         [[ 0.4814,  0.2795, -0.1042,  ...,  2.2585,  2.2181,  2.1777],\n",
       "          [ 0.4814,  0.4006, -0.1244,  ...,  2.2585,  2.2383,  2.2181],\n",
       "          [ 0.5016,  0.5016, -0.1648,  ...,  2.2988,  2.2585,  2.2383],\n",
       "          ...,\n",
       "          [ 0.3603,  0.4814,  0.3199,  ..., -0.3869, -0.5485, -0.5888],\n",
       "          [ 0.2795,  0.5218,  0.4612,  ..., -0.2254, -0.3667, -0.4879],\n",
       "          [ 0.1381,  0.5824,  0.5420,  ..., -0.1850, -0.3465, -0.4677]],\n",
       "\n",
       "         [[ 0.1567, -0.0300, -0.3472,  ...,  2.6948,  2.6575,  2.6015],\n",
       "          [ 0.1380,  0.1007, -0.3846,  ...,  2.6948,  2.6575,  2.6388],\n",
       "          [ 0.1753,  0.1753, -0.4219,  ...,  2.7134,  2.6761,  2.6575],\n",
       "          ...,\n",
       "          [-0.1233,  0.0260, -0.1046,  ..., -0.4405, -0.5712, -0.6272],\n",
       "          [-0.2166,  0.0260, -0.0113,  ..., -0.3099, -0.4219, -0.5152],\n",
       "          [-0.3472,  0.0633,  0.0633,  ..., -0.2726, -0.4032, -0.4779]]]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size = 2)\n",
    "next(iter(train_loader))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000, deep_base=True):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.deep_base = deep_base\n",
    "        if not self.deep_base:\n",
    "            self.inplanes = 64\n",
    "            self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "            self.bn1 = nn.BatchNorm2d(64)\n",
    "        else:\n",
    "            self.inplanes = 128\n",
    "            self.conv1 = conv3x3(3, 64, stride=2)\n",
    "            self.bn1 = nn.BatchNorm2d(64)\n",
    "            \n",
    "        #on a décalé\n",
    "        self.conv2 = conv3x3(64, 64)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = conv3x3(64, 64) #128)\n",
    "        self.bn3 = nn.BatchNorm2d(64) #128)\n",
    "            \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    # for the PSPNet, this forward is never used. We will still leave it for completion\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        if self.deep_base:\n",
    "            x = self.relu(self.bn2(self.conv2(x)))\n",
    "            x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPM(nn.Module):\n",
    "    def __init__(self, in_dim, reduction_dim, bins):\n",
    "        super(PPM, self).__init__()\n",
    "        self.features = []\n",
    "        for bin in bins:\n",
    "            self.features.append(nn.Sequential(\n",
    "                nn.AdaptiveAvgPool2d(bin),\n",
    "                nn.Conv2d(in_dim, reduction_dim, kernel_size=1, bias=False),\n",
    "                nn.BatchNorm2d(reduction_dim),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ))\n",
    "        self.features = nn.ModuleList(self.features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_size = x.size()\n",
    "        print(\"PPM size of x:\", x_size)\n",
    "        out = [x]\n",
    "        for f in self.features:\n",
    "            out.append(F.interpolate(f(x), x_size[2:], mode='bilinear', align_corners=True))\n",
    "        return torch.cat(out, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PSPNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSPNet(nn.Module):\n",
    "    def __init__(self, layers=50, bins=(1, 2, 3, 6), dropout=0.1, classes=10, zoom_factor=8, criterion=nn.CrossEntropyLoss(ignore_index=255), pretrained=True):\n",
    "        super(PSPNet, self).__init__()\n",
    "        assert layers in [50, 101, 152]\n",
    "        assert 2048 % len(bins) == 0\n",
    "        assert classes > 1\n",
    "        assert zoom_factor in [1, 2, 4, 8]\n",
    "        self.zoom_factor = zoom_factor\n",
    "        self.criterion = criterion    \n",
    "        \n",
    "        # resnet101: 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth'\n",
    "        #add condition if we want to remove it (see argument pretrained)\n",
    "        path_to_pretrained = \"./resnet101.pth\"\n",
    "        resnet = ResNet(Bottleneck, [3, 4, 23, 3], num_classes=1000, deep_base=False)\n",
    "        resnet.load_state_dict(torch.load(path_to_pretrained), strict=False)\n",
    "\n",
    "        \n",
    "        self.layer0 = nn.Sequential(resnet.conv1, resnet.bn1, resnet.relu, resnet.conv2, resnet.bn2, resnet.relu, resnet.conv3, resnet.bn3, resnet.relu, resnet.maxpool)\n",
    "        self.layer1, self.layer2, self.layer3, self.layer4 = resnet.layer1, resnet.layer2, resnet.layer3, resnet.layer4\n",
    "\n",
    "        \n",
    "        # change parameters for layers 3 and 4\n",
    "        for n, m in self.layer3.named_modules():\n",
    "            if 'conv2' in n:\n",
    "                m.dilation, m.padding, m.stride = (2, 2), (2, 2), (1, 1)\n",
    "            elif 'downsample.0' in n:\n",
    "                m.stride = (1, 1)\n",
    "        for n, m in self.layer4.named_modules():\n",
    "            if 'conv2' in n:\n",
    "                m.dilation, m.padding, m.stride = (4, 4), (4, 4), (1, 1)\n",
    "            elif 'downsample.0' in n:\n",
    "                m.stride = (1, 1)\n",
    "                \n",
    "                \n",
    "        # feature dimension after Resnet\n",
    "        fea_dim = 2048\n",
    "        self.ppm = PPM(fea_dim, int(fea_dim/len(bins)), bins)\n",
    "        fea_dim *= 2\n",
    "        self.cls = nn.Sequential(\n",
    "            nn.Conv2d(fea_dim, 512, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p=dropout),\n",
    "            nn.Conv2d(512, classes, kernel_size=1)\n",
    "        )\n",
    "        if self.training:\n",
    "            self.aux = nn.Sequential(\n",
    "                nn.Conv2d(1024, 256, kernel_size=3, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(256),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout2d(p=dropout),\n",
    "                nn.Conv2d(256, classes, kernel_size=1)\n",
    "            )\n",
    "\n",
    "            \n",
    "            \n",
    "    def forward(self, x, y=None):\n",
    "        x_size = x.size()\n",
    "        assert (x_size[2]-1) % 8 == 0 and (x_size[3]-1) % 8 == 0\n",
    "        h = int((x_size[2] - 1) / 8 * self.zoom_factor + 1)\n",
    "        w = int((x_size[3] - 1) / 8 * self.zoom_factor + 1)\n",
    "\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x_tmp = self.layer3(x)\n",
    "        x = self.layer4(x_tmp)\n",
    "        # use Pyramid Pooling Model\n",
    "        x = self.ppm(x)\n",
    "        x = self.cls(x)\n",
    "        if self.zoom_factor != 1:\n",
    "            x = F.interpolate(x, size=(h, w), mode='bilinear', align_corners=True)\n",
    "\n",
    "        if self.training:\n",
    "            aux = self.aux(x_tmp)\n",
    "            if self.zoom_factor != 1:\n",
    "                aux = F.interpolate(aux, size=(h, w), mode='bilinear', align_corners=True)\n",
    "            main_loss = self.criterion(x, y)\n",
    "            aux_loss = self.criterion(aux, y)\n",
    "            return x.max(1)[1], main_loss, aux_loss\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(batch, model, optimizer, aux_weight, device=\"cuda\"):\n",
    "    # TODO fill this function with the training step code\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    model.zero_grad()\n",
    "    \n",
    "    # TODO retrieve image and label from the batch\n",
    "    x, y = batch\n",
    "\n",
    "    # TODO move model and code to GPU\n",
    "    model = model.to(device)\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    \n",
    "    # TODO forward pass\n",
    "    y_hat, main_loss, aux_loss = model(x)\n",
    "    \n",
    "    # TODO loss calculation\n",
    "    loss = main_loss + aux_weight * aux_loss\n",
    "  \n",
    "    # TODO implement backprop and model update\n",
    "    loss.backward() # backpropoagation of gradients\n",
    "    optimizer.step() # update model parameters\n",
    "\n",
    "    # lets also calculate accuracy for fun\n",
    "    # FYI\n",
    "    # .cpu() moves the data back to cpu (if on GPU)\n",
    "    # .detach() removes gradients (we dont need them for accuracy)\n",
    "    # .numpy() converts the tensor to numpy for better handling later\n",
    "    predictions = y_hat.argmax(1).cpu().detach().numpy()\n",
    "    ground_truth = y.cpu().detach().numpy()\n",
    "    \n",
    "    # accuracy is the mean of correct (1) and incorrect (0) classifications\n",
    "    accuracy = (predictions == ground_truth).mean()\n",
    "  \n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(train_dl, model, optimizer, aux_weight):\n",
    "    \n",
    "    # collect some statistics\n",
    "    losses, accuracies = [], []\n",
    "    \n",
    "    for batch in train_dl:\n",
    "        print(\"new batch\")\n",
    "        # TODO call training_step\n",
    "        loss, accuracy = training_step(batch, model, optimizer, aux_weight, device = \"cpu\")\n",
    "        \n",
    "        # append statistics\n",
    "        losses.append(loss.cpu().detach().numpy())\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    # return averaged losses and accuracies\n",
    "    return np.stack(losses).mean(), np.stack(accuracies).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "model = PSPNet()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new batch\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\CPUAllocator.cpp:76] data. DefaultCPUAllocator: not enough memory: you tried to allocate 530841600 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5148/2421421926.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# TODO: call train_epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mtrainloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainaccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maux_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"epoch {epoch}; trainloss {trainloss:.2f}, train accuracy {trainaccuracy*100:.2f}%\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5148/387377237.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(train_dl, model, optimizer, aux_weight)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"new batch\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;31m# TODO call training_step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maux_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"cpu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;31m# append statistics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5148/3337631777.py\u001b[0m in \u001b[0;36mtraining_step\u001b[1;34m(batch, model, optimizer, aux_weight, device)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m# TODO forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0my_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maux_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m# TODO loss calculation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5148/3923648432.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[0mx_tmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_tmp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;31m# use Pyramid Pooling Model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5148/737193637.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    440\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 442\u001b[1;33m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[0;32m    443\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\CPUAllocator.cpp:76] data. DefaultCPUAllocator: not enough memory: you tried to allocate 530841600 bytes."
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "aux_weight = 0.5\n",
    "\n",
    "stats = []\n",
    "for epoch in range(num_epochs):\n",
    "    # TODO: call train_epoch\n",
    "    trainloss, trainaccuracy = train_epoch(train_loader, model, optimizer, aux_weight)\n",
    "    \n",
    "    print(f\"epoch {epoch}; trainloss {trainloss:.2f}, train accuracy {trainaccuracy*100:.2f}%\")\n",
    "\n",
    "    stats.append({\n",
    "        \"trainloss\":float(trainloss),\n",
    "        \"trainaccuracy\":float(trainaccuracy),\n",
    "        \"epoch\":epoch\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlosses = np.stack([stat[\"trainloss\"] for stat in stats])\n",
    "trainaccuracy = np.stack([stat[\"trainaccuracy\"] for stat in stats])\n",
    "epoch = np.stack([stat[\"epoch\"] for stat in stats])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(epoch, trainaccuracy)\n",
    "ax.set_xlabel(\"epoch\")\n",
    "ax.set_ylabel(\"train accuracy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
